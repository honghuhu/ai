{"nbformat":4,"nbformat_minor":0,"metadata":{"coursera":{"course_slug":"convolutional-neural-networks","graded_item_id":"bwbJV","launcher_item_id":"0TkXB"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"16_UseTensorflowBuildCNN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"XXgDCahz8dHi"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/explore/ai/14_16_cnn\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-F4OvhlF8O9e"},"source":["# 使用TF构建卷积神经网络\n","在这篇notebook文档中，我们将:\n","\n","- 实现一些工具函数\n","- 利用这些函数构建一个功能完整的CNN\n","\n","通过本文档，你将学会使用TensorFlow创建并训练CNN来进行图像分类。\n","\n","**本篇文档需要的tensorflow是1.2.1。所以我们首先要调整电脑上的tensorflow版本。**\n","\n","方法如下\n","\n","- 关闭所有浏览器和jupyter notebook。当然也包括关闭本文档了。\n","- 从window菜单里打开Anaconda Prompt\n","- 在里面执行activate tensorflow命令\n","- 然后在里面执行pip install tensorflow==1.2.1 --upgrade\n","- 成功后再打开本文档\n","\n","开发环境的不同，有时候可能会导致很莫名其妙的问题，所以大家一定要保持与我的开发环境一致。"]},{"cell_type":"markdown","metadata":{"id":"VG2bDn288O9i"},"source":["## 1.0 - 准备数据集\n","\n","首先，还是要加载一些工具库"]},{"cell_type":"code","metadata":{"id":"8LCqRZWs8O9i","executionInfo":{"status":"aborted","timestamp":1631451094679,"user_tz":-480,"elapsed":21,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["import math\n","import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","import scipy\n","from PIL import Image\n","from scipy import ndimage\n","import tensorflow as tf\n","from tensorflow.python.framework import ops\n","from cnn_utils import *\n","\n","%matplotlib inline\n","np.random.seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LtAPfA_r8O9k"},"source":["运行下面的单元来加载数据集,它里面包含的是0到5的手势。"]},{"cell_type":"code","metadata":{"id":"P3WJ03rf8O9k","executionInfo":{"status":"aborted","timestamp":1631451094680,"user_tz":-480,"elapsed":22,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kclVlbRY8O9l"},"source":["*斜体文本*<img width=800 src=\"https://z3.ax1x.com/2021/09/12/49luQI.png\">\n","\n","下面的单元会将数据集里面的某个样本的图片已经它对应的数字打印出来。你可以更改一下index的值，让它打印出不同的样本。"]},{"cell_type":"code","metadata":{"id":"psN3zRIL8O9m","executionInfo":{"status":"aborted","timestamp":1631451094681,"user_tz":-480,"elapsed":22,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["index = 6\n","plt.imshow(X_train_orig[index])\n","print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7RQCN_G68O9n"},"source":["其实在第二章的时候，我们就已经接触了这个数据集。当时我们是在它上面构建了一个全链接神经网络。其实我们应该使用CNN，因为这些数据是图片。就如我们教程中所说的，只要提到智能视觉，那么就应该想到CNN。\n","\n","下面我们先把这些数据的维度打印出来。因为编程中常常会出现因为维度错乱而导致bug出现。而且一旦出现了还很不好查，所以我们会在很多地方把维度信息打印出来。即可以防止出现维度错乱，又可以在出现bug后帮助定位问题。"]},{"cell_type":"code","metadata":{"id":"fcMyv1ei8O9n","executionInfo":{"status":"aborted","timestamp":1631451094682,"user_tz":-480,"elapsed":23,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["X_train = X_train_orig/255.\n","X_test = X_test_orig/255.\n","Y_train = convert_to_one_hot(Y_train_orig, 6).T\n","Y_test = convert_to_one_hot(Y_test_orig, 6).T\n","print (\"训练样本数 = \" + str(X_train.shape[0]))\n","print (\"测试样本数 = \" + str(X_test.shape[0]))\n","print (\"X_train的维度: \" + str(X_train.shape))\n","print (\"Y_train的维度: \" + str(Y_train.shape))\n","print (\"X_test的维度: \" + str(X_test.shape))\n","print (\"Y_test的维度: \" + str(Y_test.shape))\n","conv_layers = {}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"IDUOfCBR8O9o"},"source":["### 1.1 - 创建占位符（placeholders）\n","\n","要使用TensorFlow，首先我们需要为训练数据准备好占位符，这样一来，在运行tensorflow session时我们就可以把数据填充到占位符中供TensorFlow使用。\n","\n","下面的函数会为样本X和标签Y分别创建占位符。在代码中我们没有指定样本的数量，因为这样会使代码更加灵活，可以让我们在后面才决定样本数量。"]},{"cell_type":"code","metadata":{"id":"pux8pXfo8O9o","executionInfo":{"status":"aborted","timestamp":1631451094683,"user_tz":-480,"elapsed":24,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["def create_placeholders(n_H0, n_W0, n_C0, n_y):\n","    \"\"\"    \n","    参数:\n","    n_H0 -- 图像矩阵的高\n","    n_W0 -- 图像矩阵的宽\n","    n_C0 -- 图像矩阵的深度\n","    n_y -- 标签类别数量，我们的数据集是0到5的手势，所以有6个类别\n","        \n","    返回值:\n","    X -- 样本数据的占位符\n","    Y -- 标签的占位符\n","    \"\"\"\n","    # tf.compat.v1.disable_eager_execution()\n"," \n","    # 下面使用None来表示样本数量，表示当前还不确定样本数量\n","    X = tf.compat.v1.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n","    Y = tf.compat.v1.placeholder(tf.float32, [None, n_y])\n","    \n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH-HdA9j8O9p","executionInfo":{"status":"aborted","timestamp":1631451094684,"user_tz":-480,"elapsed":25,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["X, Y = create_placeholders(64, 64, 3, 6)\n","print (\"X = \" + str(X))\n","print (\"Y = \" + str(Y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKeP5q228O9p"},"source":["### 1.2 - 初始化参数\n"]},{"cell_type":"code","metadata":{"id":"1VXORLs58O9p","executionInfo":{"status":"aborted","timestamp":1631451094685,"user_tz":-480,"elapsed":26,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["def initialize_parameters():\n","    \n","    tf.compat.v1.set_random_seed(1)                            \n","        \n","    #使用`tf.contrib.layers.xavier_initializer(seed = 0)`来初始化W1。\n","    # W1的维度是[4, 4, 3, 8],表示第一个卷积层过滤器矩阵的[高，宽，深度，个数]\n","    W1 = tf.compat.v1.get_variable(\"W1\", [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n","    #初始化W2\n","    W2 = tf.compat.v1.get_variable(\"W2\", [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n","    \n","    #有同学会问，为什么不初始化阈值和全连接层的相关参数呢？\n","    #因为TensorFlow会自动初始化它们，不需要我们操心\n","\n","    parameters = {\"W1\": W1,\n","                  \"W2\": W2}\n","    \n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oMjL2J38O9q","executionInfo":{"status":"aborted","timestamp":1631451094686,"user_tz":-480,"elapsed":27,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["tf.compat.v1.reset_default_graph()\n","with tf.compat.v1.Session() as sess_test:\n","    parameters = initialize_parameters()\n","    init = tf.global_variables_initializer()\n","    sess_test.run(init)\n","    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n","    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_iWAPhwW8O9q"},"source":["### 1.2 - 前向传播\n","\n","TensorFlow提供了一些CNN相关的工具函数。\n","\n","- **tf.nn.conv2d(X,W1, strides = [1,s,s,1], padding = 'SAME'):** X是指输入矩阵，W1是指过滤器。这个函数会将X和W1进行卷积。strides是指各个维度的卷积步长，[1,s,s,1]的含义分别是[样本数，输入矩阵的高，输入矩阵的宽，输入矩阵的深度]。padding是指填补数量，默认使用SAME填补，也就是自动填补一定数量元素而保证输入矩阵与输出矩阵的尺寸一样。\n","\n","\n","- **tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME'):** 这个函数会对输入矩阵A进行最大池化。ksize中的f表示池化窗口的大小。strides中的s表示步长。\n","\n","\n","- **tf.nn.relu(Z1):** 对Z1中的每一个元素进行relu激活\n","\n","\n","- **tf.contrib.layers.flatten(P)**: 它会将P中样本的矩阵扁平化成向量。\n","\n","\n","- **tf.contrib.layers.fully_connected(F, num_outputs):** 构建一个全连接层，F是该层的输入，num_outputs表示该层中神经元的个数。这个函数会自动初始化该层的权重w。我们在前面只初始化了卷积层相关的参数,因为TensorFlow会自动帮我们初始化全链接层的参数。"]},{"cell_type":"code","metadata":{"id":"33KYMZfl8O9q","executionInfo":{"status":"aborted","timestamp":1631451094687,"user_tz":-480,"elapsed":27,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["def forward_propagation(X, parameters):\n","    \"\"\"\n","    这个函数会实现如下的前向传播流程:\n","    CONV2D卷积 -> RELU激活 -> MAXPOOL池化 -> CONV2D卷积 -> RELU激活 -> MAXPOOL池化 -> FLATTEN扁平化 -> 全连接层\n","    \n","    参数:\n","    X -- 输入特征的占位符\n","    parameters -- 之前我们初始化好的\"W1\", \"W2\"参数\n","\n","    Returns:\n","    Z3 -- 最后一个全连接层的输出\n","    \"\"\"\n","    \n","    W1 = parameters['W1']\n","    W2 = parameters['W2']\n","    \n","    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n","\n","    A1 = tf.nn.relu(Z1)\n","    \n","    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding='SAME')\n","\n","    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n","\n","    A2 = tf.nn.relu(Z2)\n","    \n","    P2 = tf.nn.max_pool(A2, ksize = [1, 4, 4, 1], strides = [1, 4, 4, 1], padding='SAME')\n","\n","    P = tf.contrib.layers.flatten(P2)\n","    # 指定该全连接层有6个神经元。\n","    # activation_fn=None表示该层没有激活函数，因为后面我们会再接一个softmax层\n","    Z3 = tf.contrib.layers.fully_connected(P, 6, activation_fn=None)\n","\n","    return Z3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ns-SEHq8O9r","executionInfo":{"status":"aborted","timestamp":1631451094690,"user_tz":-480,"elapsed":30,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["tf.reset_default_graph()\n","with tf.Session() as sess:\n","    np.random.seed(1)\n","    X, Y = create_placeholders(64, 64, 3, 6)\n","    parameters = initialize_parameters()\n","    Z3 = forward_propagation(X, parameters)\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)})\n","    print(\"Z3 = \" + str(a))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1CHV0Cao8O9s"},"source":["### 1.3 - 计算损失"]},{"cell_type":"code","metadata":{"id":"SS1Uv1Bc8O9s","executionInfo":{"status":"aborted","timestamp":1631451094691,"user_tz":-480,"elapsed":31,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["def compute_cost(Z3, Y):\n","    \"\"\"\n","    参数:\n","    Z3 -- 前面forward_propagation的输出结果，维度是(6, 样本数)\n","    Y -- 真实标签的占位符，维度当然也是(6, 样本数)\n","    \n","    返回值:\n","    cost - 返回一个tensorflow张量，它代表了softmax激活以及成本计算操作。\n","    \"\"\"\n","    \n","    # tf.nn.softmax_cross_entropy_with_logits函数不仅仅执行了softmax激活，还将成本也给计算了。\n","    # tf.reduce_mean本用来获取平均值。在这里被用于获取多个样本的平均损失，即获取成本。\n","    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n","    \n","    return cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpN_mwk38O9s","executionInfo":{"status":"aborted","timestamp":1631451094692,"user_tz":-480,"elapsed":32,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["tf.reset_default_graph()\n","\n","with tf.Session() as sess:\n","    np.random.seed(1)\n","    X, Y = create_placeholders(64, 64, 3, 6)\n","    parameters = initialize_parameters()\n","    Z3 = forward_propagation(X, parameters)\n","    cost = compute_cost(Z3, Y)\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","    a = sess.run(cost, {X: np.random.randn(4,64,64,3), Y: np.random.randn(4,6)})\n","    print(\"cost = \" + str(a))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lG99F2-_8O9t"},"source":["## 1.4 构建模型\n","\n","最终，我们将上面那些工具函数组合起来，构建一个CNN网络模型。并且用手势数据集来训练它。"]},{"cell_type":"code","metadata":{"id":"IcoIR94E8O9t","executionInfo":{"status":"aborted","timestamp":1631451094692,"user_tz":-480,"elapsed":31,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["def model(X_train, Y_train, X_test, Y_test, learning_rate=0.009,\n","          num_epochs=100, minibatch_size=64, print_cost=True):\n","    \"\"\"\n","    参数:\n","    X_train -- 训练集数据，维度是(1080, 64, 64, 3)\n","    Y_train -- 训练集标签, 维度是(1080, 6)\n","    X_test -- 测试集数据, 维度是(120, 64, 64, 3)\n","    Y_test -- 测试集标签, 维度是(120, 6)\n","    \n","    返回值:\n","    train_accuracy -- 训练集上的预测精准度\n","    test_accuracy -- 测试集上的预测精准度\n","    parameters -- 训练好的参数\n","    \"\"\"\n","    \n","    ops.reset_default_graph()                         # 重置一下tf框架\n","    tf.set_random_seed(1)                       \n","    seed = 3                                       \n","    (m, n_H0, n_W0, n_C0) = X_train.shape             \n","    n_y = Y_train.shape[1]   # n_y是标签的类别数量，这里是6\n","    costs = []                                     \n","    \n","    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n","\n","    parameters = initialize_parameters()\n","\n","    Z3 = forward_propagation(X, parameters)\n","\n","    cost = compute_cost(Z3, Y)\n","\n","    \n","    # 我们使用adam来作为优化算法\n","    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n","    \n","    init = tf.global_variables_initializer()\n","     \n","    with tf.Session() as sess:\n","        \n","        sess.run(init)\n","        \n","        for epoch in range(num_epochs):\n","\n","            minibatch_cost = 0.\n","            num_minibatches = int(m / minibatch_size) \n","            seed = seed + 1\n","            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n","\n","            for minibatch in minibatches:\n","\n","                (minibatch_X, minibatch_Y) = minibatch\n","                # 执行session。训练正式开始。每一次训练一个子训练集minibatch\n","                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n","                \n","                minibatch_cost += temp_cost / num_minibatches\n","                \n","\n","            if print_cost == True and epoch % 5 == 0:\n","                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n","            if print_cost == True and epoch % 1 == 0:\n","                costs.append(minibatch_cost)\n","        \n","        plt.plot(np.squeeze(costs))\n","        plt.ylabel('cost')\n","        plt.xlabel('iterations (per tens)')\n","        plt.title(\"Learning rate =\" + str(learning_rate))\n","        plt.show()\n","\n","        # 计算预测精准度\n","        predict_op = tf.argmax(Z3, 1)\n","        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n","        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","        print(accuracy)\n","        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n","        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n","        print(\"训练集预测精准度:\", train_accuracy)\n","        print(\"测试集预测精准度:\", test_accuracy)\n","                \n","        return train_accuracy, test_accuracy, parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9OmOz9Ni8O9t","executionInfo":{"status":"aborted","timestamp":1631451094693,"user_tz":-480,"elapsed":32,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["_, _, parameters = model(X_train, Y_train, X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1c5nEf28O9u"},"source":["预测精准度有可能会上下浮动一点点。"]},{"cell_type":"markdown","metadata":{"id":"zSxrs37T8O9u"},"source":["训练集预测精准度: 0.86851853\n","测试集预测精准度: 0.73333335\n","恭喜！我们一起构建了一个可以识别手语CNN程序，识别率达到了75%左右。当然，你还可以继续提升它，通过微调超参数，以及使用我们在第3章中学到的知识来分析优化它。\n","\n","坚持跟我学到了现在，值得表扬，给你个大拇指！去逛逛放松放松吧！"]},{"cell_type":"code","metadata":{"id":"Bweu4De68O9u","executionInfo":{"status":"aborted","timestamp":1631451094694,"user_tz":-480,"elapsed":33,"user":{"displayName":"yuxiang wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09333219890846106757"}}},"source":["fname = \"images/thumbs_up.jpg\"\n","image = np.array(plt.imread(fname))\n","my_image = scipy.misc.imresize(image, size=(64,64))\n","plt.imshow(my_image)"],"execution_count":null,"outputs":[]}]}