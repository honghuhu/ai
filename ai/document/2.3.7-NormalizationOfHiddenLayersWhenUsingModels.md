### 2.3.7 使用模型时的隐藏层归一化
通过前面文章的学习，我们知道了在训练模型时，可以根据训练中所有样本关联的`z`来计算归一化处理中所需的`u`和`σ`。但是在使用模型时，我们只预测一个样本，那么如何得到隐藏层归一化所需的`u`和`σ`呢? 

当然，在整个行业中有各种各样的方法来解决上面的问题。之前也经常有同学问到:"老师，我在网上其他文章中看到了有和你不一样的算法"。看到不同的算法是很正常的。本篇文章中，我也只能给大家介绍一个我认为很常见的方法--在训练时，根据所有子训练集`mini-batch`的`u`和`σ`计算得出它们的指数加权平均值，用这个平均值来进行模型使用时的归一化处理。这句话可能有点儿难理解，下面我举个实例来进行解释。

如果 $u^{\{1\}[1]}$ 是第 1 个子训练集第 1 层神经网络相关的`u`, $u^{\{2\}[1]}$ 是第 2 个子训练集第 1 层神经网络相关的`u`...那么，在使用模型时，第 1 层神经网络中相关的`u`就是 $(u^{\{1\}[1]}, u^{\{2\}[1]}...)$ 的指数加权平均值。同理，`σ`的计算也是一样的。指数加权平均值
的知识在 2.2.3 ,建议你温故一下它。